{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1983b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2, json, numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199c1c3",
   "metadata": {},
   "source": [
    "### 路径说明\n",
    "```\n",
    "FS2K\n",
    "├─data # FS2K数据集位置\n",
    "│  └─FS2K\n",
    "│      ├─photo\n",
    "│      │  ├─photo1\n",
    "│      │  ├─photo2\n",
    "│      │  └─photo3\n",
    "│      └─sketch\n",
    "│          ├─sketch1\n",
    "│          ├─sketch2\n",
    "│          └─sketch3\n",
    "├─save # 模型保存位置\n",
    "└─FS2K.ipynb # 代码\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdac8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 定义Dataset\n",
    "class DS(Dataset):\n",
    "    def __init__(s, dataD, mode='train'):\n",
    "        super().__init__()\n",
    "        s.dataD = dataD\n",
    "        s.mode = mode\n",
    "        s.xtf = transforms.Compose([\n",
    "            transforms.Resize((250,250)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        s.ytf = transforms.Compose([\n",
    "            torch.tensor,\n",
    "        ])\n",
    "        s.data = s.read()\n",
    "    \n",
    "    def read(s):\n",
    "        D = s.dataD\n",
    "        jp = D / f'anno_{s.mode}.json'\n",
    "        with jp.open('r', encoding='utf-8')as f:\n",
    "            annos = json.load(f)\n",
    "        return annos\n",
    "\n",
    "    def __getitem__(s, i):\n",
    "        a = s.data[i]\n",
    "        imgP = s.dataD/ f\"photo/{a['image_name']}.jpg\"\n",
    "        img = s.xtf(Image.open(imgP.as_posix()))\n",
    "        colors = a['lip_color']+a['eye_color']\n",
    "        attrs = list(map(int,[a['hair'],a['hair_color'],a['gender'],a['earring'],a['smile'],a['frontal_face']]))\n",
    "        return img, s.ytf(colors), torch.tensor(attrs, dtype=int)\n",
    "\n",
    "    def __len__(s):\n",
    "        return len(s.data)\n",
    "\n",
    "# 实例化Dataset\n",
    "dataD = Path('./data/FS2K')\n",
    "train_ds = DS(dataD)\n",
    "val_ds = DS(dataD, 'test')\n",
    "\n",
    "# 创建Dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_dl = DataLoader(val_ds, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf59a07",
   "metadata": {},
   "source": [
    "### Dataset说明\n",
    "每一个样本包含三个变量img, colors, attrs  \n",
    "img为tensor图片  \n",
    "colors为一个6元素的float类型一维数组, 前三个表示嘴唇颜色lip_color, 后三个表示眼睛颜色eye_color  \n",
    "attrs为6元素的整型一位数组, 分别为hair, hair_color, gender, earring, smile, frontal_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d058427f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([156.9775,  82.5112,  79.0000, 118.6518,  72.2589,  69.5982]),\n",
       " tensor([0, 2, 0, 1, 1, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, colors, attrs = train_ds[0]\n",
    "colors, attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb335b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_name': 'photo1/image0110',\n",
       " 'skin_patch': [163, 139],\n",
       " 'lip_color': [156.97750511247443, 82.51124744376278, 79.0],\n",
       " 'eye_color': [118.65178571428571, 72.25892857142857, 69.59821428571429],\n",
       " 'hair': 0,\n",
       " 'hair_color': 2,\n",
       " 'gender': 0,\n",
       " 'earring': 1,\n",
       " 'smile': 1,\n",
       " 'frontal_face': 1,\n",
       " 'style': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"image_name\": \"photo1/image0110\",\n",
    "\n",
    "    \"skin_patch\": [163, 139],\n",
    "    # a point of face region.\n",
    "\n",
    "    \"lip_color\": [156.97750511247443, 82.51124744376278, 79.0],\n",
    "    # the mean RGB value of lip area.\n",
    "\n",
    "    \"eye_color\": [118.65178571428571, 72.25892857142857, 69.59821428571429],\n",
    "    # the mean RGB value of eye area.\n",
    "\n",
    "    \"hair\": 0,\n",
    "    # 0: with hair, 1: without hair.\n",
    "\n",
    "    \"hair_color\": 2,\n",
    "    # 0: brown, 1: black, 2: red, 3: no-hair, 4: golden.\n",
    "\n",
    "    \"gender\": 0,\n",
    "    # 0: male, 1: female.\n",
    "\n",
    "    \"earring\": 1,\n",
    "    # 0: with earring, 1: without earring.\n",
    "\n",
    "    \"smile\": 1,\n",
    "    # 0: with smile, 1: without smile.\n",
    "\n",
    "    \"frontal_face\": 1,\n",
    "    # 0: head rotates within 30 degrees, 1: > 30 degrees\n",
    "\n",
    "    \"style\": 0\n",
    "    # Style = one of {0, 1, 2}, please refer to the sketch samples.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9561edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class _Hswish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(_Hswish, self).__init__()\n",
    "        self.relu6 = nn.ReLU6(inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.relu6(x + 3.) / 6.\n",
    "\n",
    "\n",
    "class _Hsigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(_Hsigmoid, self).__init__()\n",
    "        self.relu6 = nn.ReLU6(inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu6(x + 3.) / 6.\n",
    "\n",
    "\n",
    "class _ConvBNHswish(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "                 dilation=1, groups=1, norm_layer=nn.BatchNorm2d, **kwargs):\n",
    "        super(_ConvBNHswish, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias=False)\n",
    "        self.bn = norm_layer(out_channels)\n",
    "        self.act = _Hswish(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=4):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(in_channels // reduction, in_channels, bias=False),\n",
    "            _Hsigmoid(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, c, _, _ = x.size()\n",
    "        out = self.avg_pool(x).view(n, c)\n",
    "        out = self.fc(out).view(n, c, 1, 1)\n",
    "        return x * out.expand_as(x)\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, exp_size, kernel_size, stride, dilation=1, se=False, nl='RE',\n",
    "                 norm_layer=nn.BatchNorm2d, **kwargs):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "        self.use_res_connect = stride == 1 and in_channels == out_channels\n",
    "        if nl == 'HS':\n",
    "            act = _Hswish\n",
    "        else:\n",
    "            act = nn.ReLU\n",
    "        if se:\n",
    "            SELayer = SEModule\n",
    "        else:\n",
    "            SELayer = Identity\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # pw\n",
    "            nn.Conv2d(in_channels, exp_size, 1, bias=False),\n",
    "            norm_layer(exp_size),\n",
    "            act(True),\n",
    "            # dw\n",
    "            nn.Conv2d(exp_size, exp_size, kernel_size, stride, (kernel_size - 1) // 2 * dilation,\n",
    "                      dilation, groups=exp_size, bias=False),\n",
    "            norm_layer(exp_size),\n",
    "            SELayer(exp_size),\n",
    "            act(True),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(exp_size, out_channels, 1, bias=False),\n",
    "            norm_layer(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self, nclass=1000, mode='small', width_mult=1.0, dilated=False, norm_layer=nn.BatchNorm2d):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "        self.mode = mode\n",
    "        if mode == 'large':\n",
    "            layer1_setting = [\n",
    "                # k, exp_size, c, se, nl, s\n",
    "                [3, 16, 16, False, 'RE', 1],\n",
    "                [3, 64, 24, False, 'RE', 2],\n",
    "                [3, 72, 24, False, 'RE', 1], ]\n",
    "            layer2_setting = [\n",
    "                [5, 72, 40, True, 'RE', 2],\n",
    "                [5, 120, 40, True, 'RE', 1],\n",
    "                [5, 120, 40, True, 'RE', 1], ]\n",
    "            layer3_setting = [\n",
    "                [3, 240, 80, False, 'HS', 2],\n",
    "                [3, 200, 80, False, 'HS', 1],\n",
    "                [3, 184, 80, False, 'HS', 1],\n",
    "                [3, 184, 80, False, 'HS', 1],\n",
    "                [3, 480, 112, True, 'HS', 1],\n",
    "                [3, 672, 112, True, 'HS', 1],\n",
    "                [5, 672, 112, True, 'HS', 1], ]\n",
    "            layer4_setting = [\n",
    "                [5, 672, 160, True, 'HS', 2],\n",
    "                [5, 960, 160, True, 'HS', 1], ]\n",
    "        elif mode == 'small':\n",
    "            layer1_setting = [\n",
    "                # k, exp_size, c, se, nl, s\n",
    "                [3, 16, 16, True, 'RE', 2], ]\n",
    "            layer2_setting = [\n",
    "                [3, 72, 24, False, 'RE', 2],\n",
    "                [3, 88, 24, False, 'RE', 1], ]\n",
    "            layer3_setting = [\n",
    "                [5, 96, 40, True, 'HS', 2],\n",
    "                [5, 240, 40, True, 'HS', 1],\n",
    "                [5, 240, 40, True, 'HS', 1],\n",
    "                [5, 120, 48, True, 'HS', 1],\n",
    "                [5, 144, 48, True, 'HS', 1], ]\n",
    "            layer4_setting = [\n",
    "                [5, 288, 96, True, 'HS', 2],\n",
    "                [5, 576, 96, True, 'HS', 1],\n",
    "                [5, 576, 96, True, 'HS', 1], ]\n",
    "        else:\n",
    "            raise ValueError('Unknown mode.')\n",
    "\n",
    "        # building first layer\n",
    "        self.in_channels = int(16 * width_mult) if width_mult > 1.0 else 16\n",
    "        self.conv1 = _ConvBNHswish(3, self.in_channels, 3, 2, 1, norm_layer=norm_layer)\n",
    "\n",
    "        # building bottleneck blocks\n",
    "        self.layer1 = self._make_layer(Bottleneck, layer1_setting,\n",
    "                                       width_mult, norm_layer=norm_layer)\n",
    "        self.layer2 = self._make_layer(Bottleneck, layer2_setting,\n",
    "                                       width_mult, norm_layer=norm_layer)\n",
    "        self.layer3 = self._make_layer(Bottleneck, layer3_setting,\n",
    "                                       width_mult, norm_layer=norm_layer)\n",
    "        if dilated:\n",
    "            self.layer4 = self._make_layer(Bottleneck, layer4_setting,\n",
    "                                           width_mult, dilation=2, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.layer4 = self._make_layer(Bottleneck, layer4_setting,\n",
    "                                           width_mult, norm_layer=norm_layer)\n",
    "\n",
    "        # building last several layers\n",
    "        classifier = list()\n",
    "        if mode == 'large':\n",
    "            last_bneck_channels = int(960 * width_mult) if width_mult > 1.0 else 960\n",
    "            self.layer5 = _ConvBNHswish(self.in_channels, last_bneck_channels, 1, norm_layer=norm_layer)\n",
    "            classifier.append(nn.AdaptiveAvgPool2d(1))\n",
    "            classifier.append(nn.Conv2d(last_bneck_channels, 1280, 1))\n",
    "            classifier.append(_Hswish(True))\n",
    "#             classifier.append(nn.Conv2d(1280, nclass, 1))\n",
    "        elif mode == 'small':\n",
    "            last_bneck_channels = int(576 * width_mult) if width_mult > 1.0 else 576\n",
    "            self.layer5 = _ConvBNHswish(self.in_channels, last_bneck_channels, 1, norm_layer=norm_layer)\n",
    "            classifier.append(SEModule(last_bneck_channels))\n",
    "            classifier.append(nn.AdaptiveAvgPool2d(1))\n",
    "            classifier.append(nn.Conv2d(last_bneck_channels, 1280, 1))\n",
    "            classifier.append(_Hswish(True))\n",
    "#             classifier.append(nn.Conv2d(1280, nclass, 1))\n",
    "        else:\n",
    "            raise ValueError('Unknown mode.')\n",
    "#         self.classifier = nn.Sequential(*classifier)\n",
    "\n",
    "        self.flat1280 = nn.Sequential(*classifier)\n",
    "        n = 1280\n",
    "        self.lip_color = nn.Conv2d(n, 3, 1)\n",
    "        self.eye_color = nn.Conv2d(n, 3, 1)\n",
    "        self.hair = nn.Conv2d(n, 2, 1)\n",
    "        self.hair_color = nn.Conv2d(n, 5, 1)\n",
    "        self.gender = nn.Conv2d(n, 2, 1)\n",
    "        self.earring = nn.Conv2d(n, 2, 1)\n",
    "        self.smile = nn.Conv2d(n, 2, 1)\n",
    "        self.frontal_face = nn.Conv2d(n, 2, 1)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _make_layer(self, block, block_setting, width_mult, dilation=1, norm_layer=nn.BatchNorm2d):\n",
    "        layers = list()\n",
    "        for k, exp_size, c, se, nl, s in block_setting:\n",
    "            out_channels = int(c * width_mult)\n",
    "            stride = s if (dilation == 1) else 1\n",
    "            exp_channels = int(exp_size * width_mult)\n",
    "            layers.append(block(self.in_channels, out_channels, exp_channels, k, stride, dilation, se, nl, norm_layer))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "#         x = self.classifier(x)\n",
    "        flat1280 = self.flat1280(x)\n",
    "#         x = x.view(x.size(0), x.size(1))\n",
    "\n",
    "        lip_color = self.lip_color(flat1280)\n",
    "        lip_color = lip_color.view(lip_color.size(0), lip_color.size(1))\n",
    "        eye_color = self.eye_color(flat1280)\n",
    "        eye_color = eye_color.view(eye_color.size(0), eye_color.size(1))\n",
    "        hair = self.hair(flat1280)\n",
    "        hair = hair.view(hair.size(0), hair.size(1))\n",
    "        hair_color = self.hair_color(flat1280)\n",
    "        hair_color = hair_color.view(hair_color.size(0), hair_color.size(1))\n",
    "        gender = self.gender(flat1280)\n",
    "        gender = gender.view(gender.size(0), gender.size(1))\n",
    "        earring = self.earring(flat1280)\n",
    "        earring = earring.view(earring.size(0), earring.size(1))\n",
    "        smile = self.smile(flat1280)\n",
    "        smile = smile.view(smile.size(0), smile.size(1))\n",
    "        frontal_face = self.frontal_face(flat1280)\n",
    "        frontal_face = frontal_face.view(frontal_face.size(0), frontal_face.size(1))\n",
    "        \n",
    "        return [lip_color, eye_color, hair, hair_color, gender, earring, smile, frontal_face]\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "def get_mobilenet_v3(mode='small', width_mult=1.0, pretrained=False, root='~/.torch/models', **kwargs):\n",
    "    model = MobileNetV3(mode=mode, width_mult=width_mult, **kwargs)\n",
    "    if pretrained:\n",
    "        raise ValueError(\"Not support pretrained\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def mobilenet_v3_large_1_0(**kwargs):\n",
    "    return get_mobilenet_v3('large', 1.0, **kwargs)\n",
    "\n",
    "\n",
    "def mobilenet_v3_small_1_0(**kwargs):\n",
    "    return get_mobilenet_v3('small', 1.0, **kwargs)\n",
    "\n",
    "\n",
    "class Loss(torch.nn.Module):\n",
    "    def __init__(s):\n",
    "        super().__init__()\n",
    "        s.MSE = torch.nn.MSELoss()\n",
    "        s.CE = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(s, preds, colors_b, attrs_b):\n",
    "#         y = a['lip_color']+a['eye_color']+[a['hair'],a['hair_color'],a['gender'],a['earring'],a['smile'],a['frontal_face']]\n",
    "        lip_color, eye_color, hair, hair_color, gender, earring, smile, frontal_face = preds\n",
    "        lpc = s.MSE(lip_color, colors_b[:,:3])\n",
    "        lc = s.MSE(eye_color, colors_b[:,3:])\n",
    "        h = s.CE(hair, attrs_b[:, 0])\n",
    "        hc = s.CE(hair_color, attrs_b[:, 1])\n",
    "        g = s.CE(gender, attrs_b[:, 2])\n",
    "        e = s.CE(earring, attrs_b[:, 3])\n",
    "        sm = s.CE(smile, attrs_b[:, 4])\n",
    "        f = s.CE(frontal_face, attrs_b[:, 5])\n",
    "        loss = lpc+lc+h+hc+g+e+sm+f\n",
    "        \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e22db1",
   "metadata": {},
   "source": [
    "### 模型和损失函数说明\n",
    "模型使用Mobilenetv3的Small版本， 在将最后的输出层更改为8个并行的1x1卷积层，对2个颜色属性进行回归，对6个整型属性进行分类  \n",
    "回归损失使用MSE，分类损失使用交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae478728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(savePath, m, epoch, acc):\n",
    "    d = {\n",
    "        'param': m.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'acc': acc,\n",
    "    }\n",
    "    if isinstance(savePath, Path):\n",
    "        savePath = savePath.as_posix()\n",
    "    torch.save(d, savePath)\n",
    "    print('checkpoint saved as', savePath)\n",
    "\n",
    "def load(loadPath):\n",
    "    if isinstance(loadPath, Path):\n",
    "        loadPath = loadPath.as_posix()\n",
    "    d = torch.load(loadPath)\n",
    "    m = Model()\n",
    "    m.load_state_dict(d['param'])\n",
    "    print('checkpoint loaded from', loadPath)\n",
    "    e, acc = d['epoch'], d['acc']\n",
    "    print('epoch:', e, 'acc:', acc)\n",
    "    return m, d['epoch'], d['acc']\n",
    "\n",
    "def toCpu(path):\n",
    "    path = Path(path)\n",
    "    m, e, acc = load(path)\n",
    "    m.to(torch.device('cpu'))\n",
    "    save(path.parents[0]/f'{path.stem}_cpu.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9081a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(em, param, val_dl, d):\n",
    "    l=Loss()\n",
    "    vn = len(val_dl.dataset)\n",
    "    em.load_state_dict(param)\n",
    "    hair_cnt = 0\n",
    "    hair_color_cnt = 0\n",
    "    gender_cnt = 0\n",
    "    earring_cnt = 0\n",
    "    smile_cnt = 0\n",
    "    frontal_face_cnt = 0\n",
    "    L = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (xs, colors_b, attrs_b) in enumerate(val_dl):\n",
    "            xs, colors_b, attrs_b = xs.to(d), colors_b.to(d), attrs_b.to(d)\n",
    "            outs = em(xs)\n",
    "            lip_color, eye_color, hair, hair_color, gender, earring, smile, frontal_face = outs\n",
    "            L += l(outs, colors_b, attrs_b.long()).item()\n",
    "            hair_ = torch.max(hair, 1)[1]\n",
    "            hair_cnt += torch.sum(hair_ == attrs_b[:,0])\n",
    "            \n",
    "            hair_color_ = torch.max(hair_color, 1)[1]\n",
    "            hair_color_cnt += torch.sum(hair_color_ == attrs_b[:,1])\n",
    "            \n",
    "            gender_ = torch.max(gender, 1)[1]\n",
    "            gender_cnt += torch.sum(gender_ == attrs_b[:,2])\n",
    "            \n",
    "            earring_ = torch.max(earring, 1)[1]\n",
    "            earring_cnt += torch.sum(earring_ == attrs_b[:,3])\n",
    "            \n",
    "            smile_ = torch.max(smile, 1)[1]\n",
    "            smile_cnt += torch.sum(smile_ == attrs_b[:,4])\n",
    "            \n",
    "            frontal_face_ = torch.max(frontal_face, 1)[1]\n",
    "            frontal_face_cnt += torch.sum(frontal_face_ == attrs_b[:,5])\n",
    "    acc = (hair_cnt+hair_color_cnt+gender_cnt+earring_cnt+smile_cnt+frontal_face_cnt)/6/vn\n",
    "    print(f'validated on {vn} samples| mean acc:{acc*100:.4f}%')\n",
    "    print(f'hair_cnt:{hair_cnt/vn}|hair_color_cnt:{hair_color_cnt/vn}|gender_cnt:{gender_cnt/vn}')\n",
    "    print(f'earring_cnt:{earring_cnt/vn}|smile_cnt:{smile_cnt/vn}|frontal_face_cnt:{frontal_face_cnt/vn}')\n",
    "    print(f'loss:{L/vn:.4f}')\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def train(m,\n",
    "          d,\n",
    "          train_dl,\n",
    "          val_dl,\n",
    "          saveDir=Path('save'),\n",
    "          resumePath=None,\n",
    "          lr=0.001,\n",
    "          e=50,\n",
    "          s=10\n",
    "         ):\n",
    "    saveDir.mkdir(exist_ok=1)\n",
    "    startEp = -1\n",
    "    b = 0\n",
    "    try:\n",
    "        m, startEp, b = load(saveDir/'best.ckpt')\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "    if resumePath is not None:\n",
    "        m, startEp, b = load(resumePath)\n",
    "\n",
    "    m.to(d).train()\n",
    "    em = Model().to(d).eval()\n",
    "    \n",
    "    l=Loss()\n",
    "    o=torch.optim.SGD(m.parameters(), lr=lr, momentum=0.9)\n",
    "    \n",
    "    saveDir.mkdir(exist_ok=1)\n",
    "    tn = len(train_dl.dataset)\n",
    "    t = tqdm(range(startEp+1, e))\n",
    "#     t = range(startEp+1, e)\n",
    "    for ep in t:\n",
    "        L = 0\n",
    "        for i, (xs, colors_b, attrs_b) in enumerate(train_dl):\n",
    "            xs, colors_b, attrs_b = xs.to(d), colors_b.to(d), attrs_b.to(d)\n",
    "            o.zero_grad()\n",
    "            outs = m(xs)\n",
    "            loss = l(outs, colors_b, attrs_b.long())\n",
    "            loss.backward()\n",
    "            o.step()\n",
    "\n",
    "            L += loss.item()\n",
    "        t.set_description(f'ep:{ep}| L:{L/tn:.6f}')\n",
    "        if (ep+1)%s != 0: continue\n",
    "\n",
    "        acc = val(em, m.state_dict(), val_dl, d)\n",
    "        save(saveDir/f'{ep:05d}_{acc:.4f}.ckpt', m, ep, acc)\n",
    "        if b < acc:\n",
    "            b = acc\n",
    "            save(saveDir/'best.ckpt', m, ep, acc)\n",
    "        print(f'E:{ep}| L:{L/tn:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6e5fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "checkpoint loaded from save/best.ckpt\n",
      "epoch: 19 acc: tensor(0.6475, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:79| L:25.774263:   2%|▊                                                        | 60/3980 [08:45<10:51:17,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:68.8496%\n",
      "loss:45.7624\n",
      "checkpoint saved as save/00079_0.6885.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:79| L:25.774263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:159| L:14.791611:   3%|█▉                                                      | 139/3980 [20:26<9:20:25,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:73.6456%\n",
      "loss:34.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:159| L:14.791611:   4%|█▉                                                     | 140/3980 [20:30<10:48:16, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/00159_0.7365.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:159| L:14.791611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:239| L:14.686477:   6%|███                                                    | 220/3980 [32:14<10:20:14,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:72.0682%\n",
      "loss:35.3225\n",
      "checkpoint saved as save/00239_0.7207.ckpt\n",
      "E:239| L:14.686477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:319| L:9.742483:   8%|████▏                                                   | 300/3980 [43:58<10:12:28,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:73.0720%\n",
      "loss:33.4761\n",
      "checkpoint saved as save/00319_0.7307.ckpt\n",
      "E:319| L:9.742483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:399| L:6.179489:  10%|█████▎                                                  | 380/3980 [55:40<10:02:00, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:72.7055%\n",
      "loss:31.4699\n",
      "checkpoint saved as save/00399_0.7271.ckpt\n",
      "E:399| L:6.179489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:479| L:4.783745:  12%|██████▎                                                | 459/3980 [1:07:21<8:34:38,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:73.4385%\n",
      "loss:31.1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:479| L:4.783745:  12%|██████▎                                                | 460/3980 [1:07:25<9:52:21, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/00479_0.7344.ckpt\n",
      "E:479| L:4.783745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:559| L:3.239262:  14%|███████▍                                               | 540/3980 [1:19:09<9:31:58,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.0440%\n",
      "loss:30.4651\n",
      "checkpoint saved as save/00559_0.7404.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:559| L:3.239262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:639| L:3.155523:  16%|████████▌                                              | 619/3980 [1:30:49<8:09:38,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:73.9962%\n",
      "loss:31.7831\n",
      "checkpoint saved as save/00639_0.7400.ckpt\n",
      "E:639| L:3.155523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:719| L:5.851493:  18%|█████████▋                                             | 700/3980 [1:42:38<9:10:02, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.1714%\n",
      "loss:31.1979\n",
      "checkpoint saved as save/00719_0.7417.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:719| L:5.851493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:799| L:3.690464:  20%|██████████▊                                            | 779/3980 [1:54:19<7:49:16,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.2830%\n",
      "loss:31.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:799| L:3.690464:  20%|██████████▊                                            | 780/3980 [1:54:23<9:01:41, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/00799_0.7428.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:799| L:3.690464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:879| L:2.007880:  22%|███████████▉                                           | 860/3980 [2:06:09<8:47:53, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.6017%\n",
      "loss:31.1630\n",
      "checkpoint saved as save/00879_0.7460.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:879| L:2.007880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:959| L:2.708027:  24%|████████████▉                                          | 939/3980 [2:17:50<7:24:00,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.5061%\n",
      "loss:31.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:959| L:2.708027:  24%|████████████▉                                          | 940/3980 [2:17:55<8:30:34, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/00959_0.7451.ckpt\n",
      "E:959| L:2.708027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1039| L:1.773915:  26%|█████████████▌                                       | 1020/3980 [2:29:41<8:12:14,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.4105%\n",
      "loss:31.4912\n",
      "checkpoint saved as save/01039_0.7441.ckpt\n",
      "E:1039| L:1.773915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1119| L:1.836369:  28%|██████████████▋                                      | 1099/3980 [2:41:21<7:01:22,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.1555%\n",
      "loss:31.3151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1119| L:1.836369:  28%|██████████████▋                                      | 1100/3980 [2:41:26<8:07:44, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/01119_0.7416.ckpt\n",
      "E:1119| L:1.836369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1199| L:2.480325:  30%|███████████████▋                                     | 1180/3980 [2:53:12<7:44:46,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.1396%\n",
      "loss:31.4590\n",
      "checkpoint saved as save/01199_0.7414.ckpt\n",
      "E:1199| L:2.480325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1279| L:2.236263:  32%|████████████████▊                                    | 1260/3980 [3:04:57<7:30:48,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.1115%\n",
      "loss:31.5173\n",
      "checkpoint saved as save/01279_0.7511.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:1279| L:2.236263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1359| L:1.070922:  34%|█████████████████▊                                   | 1340/3980 [3:16:43<7:28:41, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.4939%\n",
      "loss:31.7062\n",
      "checkpoint saved as save/01359_0.7549.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:1359| L:1.070922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1439| L:1.078752:  36%|██████████████████▉                                  | 1420/3980 [3:28:28<7:05:43,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.5539%\n",
      "loss:31.7309\n",
      "checkpoint saved as save/01439_0.7455.ckpt\n",
      "E:1439| L:1.078752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1519| L:0.864194:  38%|███████████████████▉                                 | 1500/3980 [3:40:15<6:51:00,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.1912%\n",
      "loss:31.5557\n",
      "checkpoint saved as save/01519_0.7519.ckpt\n",
      "E:1519| L:0.864194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1599| L:1.306971:  40%|█████████████████████                                | 1580/3980 [3:52:04<6:38:43,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:73.9484%\n",
      "loss:31.7937\n",
      "checkpoint saved as save/01599_0.7395.ckpt\n",
      "E:1599| L:1.306971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1679| L:0.673257:  42%|██████████████████████                               | 1660/3980 [4:03:50<6:26:37, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.7132%\n",
      "loss:31.6911\n",
      "checkpoint saved as save/01679_0.7471.ckpt\n",
      "E:1679| L:0.673257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1759| L:0.975359:  44%|███████████████████████▏                             | 1739/3980 [4:15:31<5:28:02,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.9841%\n",
      "loss:31.8218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1759| L:0.975359:  44%|███████████████████████▏                             | 1740/3980 [4:15:35<6:19:31, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/01759_0.7498.ckpt\n",
      "E:1759| L:0.975359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1839| L:1.234064:  46%|████████████████████████▏                            | 1820/3980 [4:27:24<6:04:27, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.4742%\n",
      "loss:31.5589\n",
      "checkpoint saved as save/01839_0.7447.ckpt\n",
      "E:1839| L:1.234064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1919| L:3.235508:  48%|█████████████████████████▎                           | 1899/3980 [4:39:05<5:04:05,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.2033%\n",
      "loss:31.2094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1919| L:3.235508:  48%|█████████████████████████▎                           | 1900/3980 [4:39:09<5:50:42, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/01919_0.7420.ckpt\n",
      "E:1919| L:3.235508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1999| L:0.679710:  50%|██████████████████████████▎                          | 1980/3980 [4:50:56<5:33:31, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.0159%\n",
      "loss:32.7239\n",
      "checkpoint saved as save/01999_0.7502.ckpt\n",
      "E:1999| L:0.679710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2079| L:0.782020:  52%|███████████████████████████▍                         | 2060/3980 [5:02:42<5:19:52, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.8407%\n",
      "loss:31.3851\n",
      "checkpoint saved as save/02079_0.7484.ckpt\n",
      "E:2079| L:0.782020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2159| L:0.887377:  54%|████████████████████████████▍                        | 2140/3980 [5:14:27<5:06:04,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.7610%\n",
      "loss:31.3779\n",
      "checkpoint saved as save/02159_0.7476.ckpt\n",
      "E:2159| L:0.887377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2239| L:1.511255:  56%|█████████████████████████████▌                       | 2219/3980 [5:26:07<4:16:54,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.5379%\n",
      "loss:31.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2239| L:1.511255:  56%|█████████████████████████████▌                       | 2220/3980 [5:26:11<4:56:22, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/02239_0.7454.ckpt\n",
      "E:2239| L:1.511255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2319| L:1.663732:  58%|██████████████████████████████▋                      | 2300/3980 [5:37:56<4:42:08, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.8247%\n",
      "loss:32.0037\n",
      "checkpoint saved as save/02319_0.7482.ckpt\n",
      "E:2319| L:1.663732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2399| L:0.633089:  60%|███████████████████████████████▋                     | 2379/3980 [5:49:36<3:52:41,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.6654%\n",
      "loss:31.9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2399| L:0.633089:  60%|███████████████████████████████▋                     | 2380/3980 [5:49:41<4:28:16, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/02399_0.7467.ckpt\n",
      "E:2399| L:0.633089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2479| L:0.644041:  62%|████████████████████████████████▊                    | 2460/3980 [6:01:26<4:11:51,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.8407%\n",
      "loss:32.1221\n",
      "checkpoint saved as save/02479_0.7484.ckpt\n",
      "E:2479| L:0.644041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2559| L:0.511972:  64%|█████████████████████████████████▊                   | 2540/3980 [6:13:10<3:58:53,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.9522%\n",
      "loss:31.6928\n",
      "checkpoint saved as save/02559_0.7495.ckpt\n",
      "E:2559| L:0.511972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2639| L:0.852355:  66%|██████████████████████████████████▉                  | 2620/3980 [6:24:55<3:45:53,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.9681%\n",
      "loss:31.3675\n",
      "checkpoint saved as save/02639_0.7497.ckpt\n",
      "E:2639| L:0.852355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2719| L:0.788274:  68%|███████████████████████████████████▉                 | 2699/3980 [6:36:35<3:06:20,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.8566%\n",
      "loss:31.5759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2719| L:0.788274:  68%|███████████████████████████████████▉                 | 2700/3980 [6:36:39<3:34:40, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/02719_0.7486.ckpt\n",
      "E:2719| L:0.788274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2799| L:0.900016:  70%|█████████████████████████████████████                | 2780/3980 [6:48:25<3:22:35, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.2549%\n",
      "loss:31.9238\n",
      "checkpoint saved as save/02799_0.7525.ckpt\n",
      "E:2799| L:0.900016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2879| L:1.363165:  72%|██████████████████████████████████████               | 2860/3980 [7:00:10<3:06:03,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.7170%\n",
      "loss:31.5033\n",
      "checkpoint saved as save/02879_0.7572.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:2879| L:1.363165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2959| L:0.763866:  74%|███████████████████████████████████████▏             | 2939/3980 [7:11:50<2:32:30,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.4461%\n",
      "loss:31.4541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2959| L:0.763866:  74%|███████████████████████████████████████▏             | 2940/3980 [7:11:55<2:56:07, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/02959_0.7545.ckpt\n",
      "E:2959| L:0.763866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3039| L:0.454902:  76%|████████████████████████████████████████▏            | 3019/3980 [7:23:37<2:20:12,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.5895%\n",
      "loss:32.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3039| L:0.454902:  76%|████████████████████████████████████████▏            | 3020/3980 [7:23:41<2:42:05, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/03039_0.7559.ckpt\n",
      "E:3039| L:0.454902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3119| L:0.870610:  78%|█████████████████████████████████████████▎           | 3100/3980 [7:35:27<2:26:40, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.6533%\n",
      "loss:31.3548\n",
      "checkpoint saved as save/03119_0.7565.ckpt\n",
      "E:3119| L:0.870610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3199| L:0.488758:  80%|██████████████████████████████████████████▎          | 3179/3980 [7:47:08<1:56:39,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.0478%\n",
      "loss:32.1706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3199| L:0.488758:  80%|██████████████████████████████████████████▎          | 3180/3980 [7:47:13<2:14:37, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/03199_0.7505.ckpt\n",
      "E:3199| L:0.488758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3279| L:1.472629:  82%|███████████████████████████████████████████▍         | 3260/3980 [7:58:59<1:59:28,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.9363%\n",
      "loss:31.3515\n",
      "checkpoint saved as save/03279_0.7494.ckpt\n",
      "E:3279| L:1.472629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3359| L:0.392556:  84%|████████████████████████████████████████████▍        | 3340/3980 [8:10:45<1:47:00, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.1434%\n",
      "loss:31.3549\n",
      "checkpoint saved as save/03359_0.7514.ckpt\n",
      "E:3359| L:0.392556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3439| L:0.388047:  86%|█████████████████████████████████████████████▌       | 3420/3980 [8:22:29<1:32:46,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.2709%\n",
      "loss:31.4794\n",
      "checkpoint saved as save/03439_0.7527.ckpt\n",
      "E:3439| L:0.388047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3519| L:0.429298:  88%|██████████████████████████████████████████████▌      | 3499/3980 [8:34:13<1:10:32,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.7648%\n",
      "loss:31.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3519| L:0.429298:  88%|██████████████████████████████████████████████▌      | 3500/3980 [8:34:18<1:21:24, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/03519_0.7576.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:3519| L:0.429298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3599| L:0.343190:  90%|███████████████████████████████████████████████▋     | 3580/3980 [8:46:02<1:06:21,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:74.9681%\n",
      "loss:31.8681\n",
      "checkpoint saved as save/03599_0.7497.ckpt\n",
      "E:3599| L:0.343190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3679| L:0.356120:  92%|██████████████████████████████████████████████████▌    | 3660/3980 [8:57:48<53:16,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.5736%\n",
      "loss:31.9603\n",
      "checkpoint saved as save/03679_0.7557.ckpt\n",
      "E:3679| L:0.356120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3759| L:0.297916:  94%|███████████████████████████████████████████████████▋   | 3740/3980 [9:09:37<40:43, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.8286%\n",
      "loss:31.3931\n",
      "checkpoint saved as save/03759_0.7583.ckpt\n",
      "checkpoint saved as save/best.ckpt\n",
      "E:3759| L:0.297916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3839| L:0.412955:  96%|████████████████████████████████████████████████████▊  | 3819/3980 [9:21:21<23:35,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.4143%\n",
      "loss:31.5094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3839| L:0.412955:  96%|████████████████████████████████████████████████████▊  | 3820/3980 [9:21:25<27:02, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save/03839_0.7541.ckpt\n",
      "E:3839| L:0.412955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3919| L:0.356495:  98%|█████████████████████████████████████████████████████▉ | 3900/3980 [9:33:12<13:15,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.2071%\n",
      "loss:31.4749\n",
      "checkpoint saved as save/03919_0.7521.ckpt\n",
      "E:3919| L:0.356495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3999| L:0.282235: 100%|███████████████████████████████████████████████████████| 3980/3980 [9:44:59<00:00,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| acc:75.1434%\n",
      "loss:31.6003\n",
      "checkpoint saved as save/03999_0.7514.ckpt\n",
      "E:3999| L:0.282235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(d)\n",
    "# d = torch.device('cpu')\n",
    "Model = MobileNetV3\n",
    "m = Model().to(d)\n",
    "train(m,\n",
    "      d,\n",
    "      train_dl,\n",
    "      val_dl,\n",
    "      saveDir=Path('save'),\n",
    "#       resumePath=Path('save2/03999_0.8062.ckpt'),\n",
    "      lr=0.0001,\n",
    "      e=4000,\n",
    "      s=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06aa49de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded from save/best.ckpt\n",
      "epoch: 3759 acc: tensor(0.7583, device='cuda:0')\n",
      "validated on 1046 samples| mean acc:75.8286%\n",
      "hair_cnt:0.944550633430481|hair_color_cnt:0.5009559988975525|gender_cnt:0.8355640769004822\n",
      "earring_cnt:0.7877628803253174|smile_cnt:0.6653919816017151|frontal_face_cnt:0.8154875636100769\n",
      "loss:31.4907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7583, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em, epo, acc = load('save/best.ckpt')\n",
    "val(Model().to(d).eval(), em.state_dict(), val_dl, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74d9753a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "small\n",
      "[Errno 2] No such file or directory: 'save_small/best.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:79| L:22.012985:   2%|█▏                                                        | 79/4000 [07:16<5:59:21,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:73.4385%\n",
      "hair_cnt:0.9502868056297302|hair_color_cnt:0.44455066323280334|gender_cnt:0.7227533459663391\n",
      "earring_cnt:0.8097514510154724|smile_cnt:0.6453154683113098|frontal_face_cnt:0.8336520195007324\n",
      "loss:34.8414\n",
      "checkpoint saved as save_small/00079_0.7344.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:79| L:22.012985:   2%|█▏                                                       | 80/4000 [07:33<11:30:19, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/best.ckpt\n",
      "E:79| L:22.012985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:159| L:10.648188:   4%|██▏                                                     | 159/4000 [14:51<5:51:40,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:73.9643%\n",
      "hair_cnt:0.9502868056297302|hair_color_cnt:0.4627150893211365|gender_cnt:0.7456979155540466\n",
      "earring_cnt:0.8231357336044312|smile_cnt:0.6233269572257996|frontal_face_cnt:0.8326959609985352\n",
      "loss:31.4579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:159| L:10.648188:   4%|██▏                                                     | 160/4000 [14:55<7:00:16,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/00159_0.7396.ckpt\n",
      "checkpoint saved as save_small/best.ckpt\n",
      "E:159| L:10.648188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:239| L:5.999764:   6%|███▍                                                     | 240/4000 [22:15<6:37:02,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:74.5698%\n",
      "hair_cnt:0.949330747127533|hair_color_cnt:0.47323134541511536|gender_cnt:0.7590821981430054\n",
      "earring_cnt:0.8164435625076294|smile_cnt:0.6434034109115601|frontal_face_cnt:0.8326959609985352\n",
      "loss:30.9811\n",
      "checkpoint saved as save_small/00239_0.7457.ckpt\n",
      "checkpoint saved as save_small/best.ckpt\n",
      "E:239| L:5.999764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:319| L:5.073960:   8%|████▌                                                    | 320/4000 [29:35<6:28:15,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:74.3149%\n",
      "hair_cnt:0.9483747482299805|hair_color_cnt:0.4560229480266571|gender_cnt:0.7695984840393066\n",
      "earring_cnt:0.8183556199073792|smile_cnt:0.633843183517456|frontal_face_cnt:0.8326959609985352\n",
      "loss:30.9150\n",
      "checkpoint saved as save_small/00319_0.7431.ckpt\n",
      "E:319| L:5.073960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:399| L:3.365001:  10%|█████▋                                                   | 400/4000 [36:55<6:20:03,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.5258%\n",
      "hair_cnt:0.949330747127533|hair_color_cnt:0.4942638576030731|gender_cnt:0.7724665403366089\n",
      "earring_cnt:0.8298279047012329|smile_cnt:0.6539196968078613|frontal_face_cnt:0.8317399621009827\n",
      "loss:30.5734\n",
      "checkpoint saved as save_small/00399_0.7553.ckpt\n",
      "checkpoint saved as save_small/best.ckpt\n",
      "E:399| L:3.365001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:479| L:6.029788:  12%|██████▊                                                  | 479/4000 [44:13<5:19:49,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:74.9363%\n",
      "hair_cnt:0.949330747127533|hair_color_cnt:0.4894837439060211|gender_cnt:0.7676864266395569\n",
      "earring_cnt:0.8240917921066284|smile_cnt:0.6328871846199036|frontal_face_cnt:0.8326959609985352\n",
      "loss:30.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:479| L:6.029788:  12%|██████▊                                                  | 480/4000 [44:17<6:22:42,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/00479_0.7494.ckpt\n",
      "E:479| L:6.029788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:559| L:13.603534:  14%|███████▊                                                | 559/4000 [51:33<5:11:06,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.3505%\n",
      "hair_cnt:0.9512428045272827|hair_color_cnt:0.49713191390037537|gender_cnt:0.7829827666282654\n",
      "earring_cnt:0.8193116784095764|smile_cnt:0.6367112994194031|frontal_face_cnt:0.8336520195007324\n",
      "loss:29.9352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:559| L:13.603534:  14%|███████▊                                                | 560/4000 [51:37<6:12:36,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/00559_0.7535.ckpt\n",
      "E:559| L:13.603534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:639| L:3.310079:  16%|█████████                                                | 640/4000 [58:48<5:40:39,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.3505%\n",
      "hair_cnt:0.9531548619270325|hair_color_cnt:0.48374760150909424|gender_cnt:0.7973231077194214\n",
      "earring_cnt:0.8240917921066284|smile_cnt:0.6357552409172058|frontal_face_cnt:0.8269598484039307\n",
      "loss:30.4063\n",
      "checkpoint saved as save_small/00639_0.7535.ckpt\n",
      "E:639| L:3.310079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:719| L:9.204069:  18%|█████████▉                                             | 720/4000 [1:05:55<5:32:09,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.9720%\n",
      "hair_cnt:0.9483747482299805|hair_color_cnt:0.5038241147994995|gender_cnt:0.7925429940223694\n",
      "earring_cnt:0.8317399621009827|smile_cnt:0.6558317542076111|frontal_face_cnt:0.8260037899017334\n",
      "loss:30.1606\n",
      "checkpoint saved as save_small/00719_0.7597.ckpt\n",
      "checkpoint saved as save_small/best.ckpt\n",
      "E:719| L:9.204069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:799| L:2.554212:  20%|███████████                                            | 800/4000 [1:12:59<5:31:37,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:76.1791%\n",
      "hair_cnt:0.947418749332428|hair_color_cnt:0.5105162262916565|gender_cnt:0.7963671088218689\n",
      "earring_cnt:0.8365200757980347|smile_cnt:0.6529636383056641|frontal_face_cnt:0.8269598484039307\n",
      "loss:29.7055\n",
      "checkpoint saved as save_small/00799_0.7618.ckpt\n",
      "checkpoint saved as save_small/best.ckpt\n",
      "E:799| L:2.554212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:879| L:2.467543:  22%|████████████                                           | 880/4000 [1:20:01<5:16:09,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.3824%\n",
      "hair_cnt:0.944550633430481|hair_color_cnt:0.5|gender_cnt:0.7963671088218689\n",
      "earring_cnt:0.8173996210098267|smile_cnt:0.6558317542076111|frontal_face_cnt:0.8087953925132751\n",
      "loss:30.5938\n",
      "checkpoint saved as save_small/00879_0.7538.ckpt\n",
      "E:879| L:2.467543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:959| L:2.788131:  24%|█████████████▏                                         | 959/4000 [1:27:15<4:35:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.8923%\n",
      "hair_cnt:0.9483747482299805|hair_color_cnt:0.5133843421936035|gender_cnt:0.8049713373184204\n",
      "earring_cnt:0.8068833351135254|smile_cnt:0.6644359230995178|frontal_face_cnt:0.8154875636100769\n",
      "loss:29.9476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:959| L:2.788131:  24%|█████████████▏                                         | 960/4000 [1:27:19<5:34:21,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/00959_0.7589.ckpt\n",
      "E:959| L:2.788131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1039| L:3.166361:  26%|█████████████▊                                       | 1039/4000 [1:34:37<4:30:37,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:76.2110%\n",
      "hair_cnt:0.937858521938324|hair_color_cnt:0.5124282836914062|gender_cnt:0.8135755062103271\n",
      "earring_cnt:0.8183556199073792|smile_cnt:0.6596558094024658|frontal_face_cnt:0.8307839035987854\n",
      "loss:31.1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1039| L:3.166361:  26%|█████████████▊                                       | 1040/4000 [1:34:41<5:22:13,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/01039_0.7621.ckpt\n",
      "checkpoint saved as save_small/best.ckpt\n",
      "E:1039| L:3.166361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1119| L:1.732219:  28%|██████████████▊                                      | 1120/4000 [1:42:01<5:06:12,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.9560%\n",
      "hair_cnt:0.9502868056297302|hair_color_cnt:0.504780113697052|gender_cnt:0.8145315647125244\n",
      "earring_cnt:0.8097514510154724|smile_cnt:0.6539196968078613|frontal_face_cnt:0.8240917921066284\n",
      "loss:30.6217\n",
      "checkpoint saved as save_small/01119_0.7596.ckpt\n",
      "E:1119| L:1.732219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1199| L:1.041285:  30%|███████████████▉                                     | 1199/4000 [1:49:18<4:13:31,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:76.2588%\n",
      "hair_cnt:0.9512428045272827|hair_color_cnt:0.5200764536857605|gender_cnt:0.7992351651191711\n",
      "earring_cnt:0.8154875636100769|smile_cnt:0.6673040390014648|frontal_face_cnt:0.8221797347068787\n",
      "loss:29.4773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1199| L:1.041285:  30%|███████████████▉                                     | 1200/4000 [1:49:22<5:09:24,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/01199_0.7626.ckpt\n",
      "checkpoint saved as save_small/best.ckpt\n",
      "E:1199| L:1.041285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1279| L:1.247643:  32%|████████████████▉                                    | 1279/4000 [1:56:39<4:08:59,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.5736%\n",
      "hair_cnt:0.942638635635376|hair_color_cnt:0.490439772605896|gender_cnt:0.8001912236213684\n",
      "earring_cnt:0.8279158473014832|smile_cnt:0.6434034109115601|frontal_face_cnt:0.8298279047012329\n",
      "loss:30.2038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1279| L:1.247643:  32%|████████████████▉                                    | 1280/4000 [1:56:42<4:55:14,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/01279_0.7557.ckpt\n",
      "E:1279| L:1.247643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1359| L:1.127884:  34%|██████████████████                                   | 1360/4000 [2:04:02<4:39:16,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.1912%\n",
      "hair_cnt:0.9435946345329285|hair_color_cnt:0.49235180020332336|gender_cnt:0.8068833351135254\n",
      "earring_cnt:0.8078393936157227|smile_cnt:0.6510516405105591|frontal_face_cnt:0.8097514510154724\n",
      "loss:29.7097\n",
      "checkpoint saved as save_small/01359_0.7519.ckpt\n",
      "E:1359| L:1.127884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1439| L:0.936256:  36%|███████████████████                                  | 1439/4000 [2:11:16<3:51:24,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.7808%\n",
      "hair_cnt:0.9464626908302307|hair_color_cnt:0.5066921710968018|gender_cnt:0.8126195073127747\n",
      "earring_cnt:0.8212236762046814|smile_cnt:0.6357552409172058|frontal_face_cnt:0.8240917921066284\n",
      "loss:30.1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1439| L:0.936256:  36%|███████████████████                                  | 1440/4000 [2:11:20<4:34:00,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/01439_0.7578.ckpt\n",
      "E:1439| L:0.936256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1519| L:1.144334:  38%|████████████████████▏                                | 1520/4000 [2:18:38<4:26:29,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.7489%\n",
      "hair_cnt:0.944550633430481|hair_color_cnt:0.5152963399887085|gender_cnt:0.8173996210098267\n",
      "earring_cnt:0.8107074499130249|smile_cnt:0.6300191283226013|frontal_face_cnt:0.8269598484039307\n",
      "loss:29.8154\n",
      "checkpoint saved as save_small/01519_0.7575.ckpt\n",
      "E:1519| L:1.144334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1599| L:0.933780:  40%|█████████████████████▏                               | 1600/4000 [2:25:57<4:14:42,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.0319%\n",
      "hair_cnt:0.9416825771331787|hair_color_cnt:0.49713191390037537|gender_cnt:0.7973231077194214\n",
      "earring_cnt:0.8078393936157227|smile_cnt:0.6328871846199036|frontal_face_cnt:0.8250477910041809\n",
      "loss:29.9984\n",
      "checkpoint saved as save_small/01599_0.7503.ckpt\n",
      "E:1599| L:0.933780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1679| L:0.770723:  42%|██████████████████████▏                              | 1679/4000 [2:33:11<3:29:10,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.3824%\n",
      "hair_cnt:0.9455066919326782|hair_color_cnt:0.4961759150028229|gender_cnt:0.8040152788162231\n",
      "earring_cnt:0.7992351651191711|smile_cnt:0.6596558094024658|frontal_face_cnt:0.8183556199073792\n",
      "loss:30.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1679| L:0.770723:  42%|██████████████████████▎                              | 1680/4000 [2:33:15<4:09:28,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/01679_0.7538.ckpt\n",
      "E:1679| L:0.770723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1759| L:1.129872:  44%|███████████████████████▎                             | 1759/4000 [2:40:29<3:21:38,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.3027%\n",
      "hair_cnt:0.9464626908302307|hair_color_cnt:0.4894837439060211|gender_cnt:0.8116634488105774\n",
      "earring_cnt:0.8164435625076294|smile_cnt:0.6443594694137573|frontal_face_cnt:0.8097514510154724\n",
      "loss:30.1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1759| L:1.129872:  44%|███████████████████████▎                             | 1760/4000 [2:40:33<4:01:51,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/01759_0.7530.ckpt\n",
      "E:1759| L:1.129872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1839| L:0.643504:  46%|████████████████████████▍                            | 1840/4000 [2:47:50<3:46:02,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.1593%\n",
      "hair_cnt:0.9455066919326782|hair_color_cnt:0.49713191390037537|gender_cnt:0.8049713373184204\n",
      "earring_cnt:0.8135755062103271|smile_cnt:0.6453154683113098|frontal_face_cnt:0.8030592799186707\n",
      "loss:30.4402\n",
      "checkpoint saved as save_small/01839_0.7516.ckpt\n",
      "E:1839| L:0.643504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1919| L:1.229690:  48%|█████████████████████████▍                           | 1919/4000 [2:55:06<3:10:32,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:74.6176%\n",
      "hair_cnt:0.9541109204292297|hair_color_cnt:0.49330782890319824|gender_cnt:0.7973231077194214\n",
      "earring_cnt:0.7954111099243164|smile_cnt:0.6252390146255493|frontal_face_cnt:0.8116634488105774\n",
      "loss:31.8085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1919| L:1.229690:  48%|█████████████████████████▍                           | 1920/4000 [2:55:10<3:45:14,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/01919_0.7462.ckpt\n",
      "E:1919| L:1.229690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:1999| L:1.487875:  50%|██████████████████████████▍                          | 1999/4000 [3:02:25<3:02:16,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.3983%\n",
      "hair_cnt:0.9455066919326782|hair_color_cnt:0.5105162262916565|gender_cnt:0.8135755062103271\n",
      "earring_cnt:0.8001912236213684|smile_cnt:0.6443594694137573|frontal_face_cnt:0.8097514510154724\n",
      "loss:31.6838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:1999| L:1.487875:  50%|██████████████████████████▌                          | 2000/4000 [3:02:29<3:38:07,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/01999_0.7540.ckpt\n",
      "E:1999| L:1.487875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2079| L:0.779350:  52%|███████████████████████████▌                         | 2079/4000 [3:09:47<2:55:40,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:74.9681%\n",
      "hair_cnt:0.9483747482299805|hair_color_cnt:0.5066921710968018|gender_cnt:0.8011472225189209\n",
      "earring_cnt:0.8059273362159729|smile_cnt:0.6271510720252991|frontal_face_cnt:0.8087953925132751\n",
      "loss:30.6621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2079| L:0.779350:  52%|███████████████████████████▌                         | 2080/4000 [3:09:50<3:27:24,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/02079_0.7497.ckpt\n",
      "E:2079| L:0.779350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2159| L:1.240639:  54%|████████████████████████████▌                        | 2159/4000 [3:17:07<2:46:49,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:74.3945%\n",
      "hair_cnt:0.9369024634361267|hair_color_cnt:0.4799235165119171|gender_cnt:0.7954111099243164\n",
      "earring_cnt:0.7839388251304626|smile_cnt:0.6558317542076111|frontal_face_cnt:0.8116634488105774\n",
      "loss:30.9324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2159| L:1.240639:  54%|████████████████████████████▌                        | 2160/4000 [3:17:11<3:19:30,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/02159_0.7439.ckpt\n",
      "E:2159| L:1.240639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2239| L:0.915213:  56%|█████████████████████████████▋                       | 2240/4000 [3:24:31<3:07:01,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.2231%\n",
      "hair_cnt:0.944550633430481|hair_color_cnt:0.4799235165119171|gender_cnt:0.8221797347068787\n",
      "earring_cnt:0.8059273362159729|smile_cnt:0.6491395831108093|frontal_face_cnt:0.8116634488105774\n",
      "loss:29.9377\n",
      "checkpoint saved as save_small/02239_0.7522.ckpt\n",
      "E:2239| L:0.915213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2319| L:0.652114:  58%|██████████████████████████████▋                      | 2320/4000 [3:31:50<2:58:02,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:74.6176%\n",
      "hair_cnt:0.944550633430481|hair_color_cnt:0.4703632891178131|gender_cnt:0.7982791662216187\n",
      "earring_cnt:0.8087953925132751|smile_cnt:0.6481835246086121|frontal_face_cnt:0.8068833351135254\n",
      "loss:30.5459\n",
      "checkpoint saved as save_small/02319_0.7462.ckpt\n",
      "E:2319| L:0.652114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2399| L:0.803669:  60%|███████████████████████████████▊                     | 2399/4000 [3:39:08<2:24:53,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.3665%\n",
      "hair_cnt:0.9464626908302307|hair_color_cnt:0.49713191390037537|gender_cnt:0.8202676773071289\n",
      "earring_cnt:0.8068833351135254|smile_cnt:0.6357552409172058|frontal_face_cnt:0.8154875636100769\n",
      "loss:30.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2399| L:0.803669:  60%|███████████████████████████████▊                     | 2400/4000 [3:39:11<2:53:37,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/02399_0.7537.ckpt\n",
      "E:2399| L:0.803669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2479| L:0.842732:  62%|████████████████████████████████▊                    | 2479/4000 [3:46:31<2:19:04,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.1434%\n",
      "hair_cnt:0.9464626908302307|hair_color_cnt:0.4894837439060211|gender_cnt:0.8059273362159729\n",
      "earring_cnt:0.8059273362159729|smile_cnt:0.6500955820083618|frontal_face_cnt:0.8107074499130249\n",
      "loss:31.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2479| L:0.842732:  62%|████████████████████████████████▊                    | 2480/4000 [3:46:35<2:45:26,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/02479_0.7514.ckpt\n",
      "E:2479| L:0.842732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2559| L:0.659187:  64%|█████████████████████████████████▉                   | 2560/4000 [3:53:54<2:33:36,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.6533%\n",
      "hair_cnt:0.95219886302948|hair_color_cnt:0.495219886302948|gender_cnt:0.8116634488105774\n",
      "earring_cnt:0.8078393936157227|smile_cnt:0.6539196968078613|frontal_face_cnt:0.8183556199073792\n",
      "loss:31.6160\n",
      "checkpoint saved as save_small/02559_0.7565.ckpt\n",
      "E:2559| L:0.659187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2639| L:0.655564:  66%|██████████████████████████████████▉                  | 2639/4000 [4:01:08<2:02:37,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.7011%\n",
      "hair_cnt:0.9455066919326782|hair_color_cnt:0.495219886302948|gender_cnt:0.8260037899017334\n",
      "earring_cnt:0.7992351651191711|smile_cnt:0.6644359230995178|frontal_face_cnt:0.8116634488105774\n",
      "loss:31.8464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2639| L:0.655564:  66%|██████████████████████████████████▉                  | 2640/4000 [4:01:12<2:25:33,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/02639_0.7570.ckpt\n",
      "E:2639| L:0.655564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2719| L:0.641298:  68%|████████████████████████████████████                 | 2719/4000 [4:08:23<1:54:47,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.3824%\n",
      "hair_cnt:0.947418749332428|hair_color_cnt:0.5038241147994995|gender_cnt:0.8173996210098267\n",
      "earring_cnt:0.8021032214164734|smile_cnt:0.6424474120140076|frontal_face_cnt:0.8097514510154724\n",
      "loss:31.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2719| L:0.641298:  68%|████████████████████████████████████                 | 2720/4000 [4:08:27<2:16:59,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/02719_0.7538.ckpt\n",
      "E:2719| L:0.641298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2799| L:0.731466:  70%|█████████████████████████████████████                | 2800/4000 [4:15:47<2:06:50,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.3824%\n",
      "hair_cnt:0.9531548619270325|hair_color_cnt:0.49808794260025024|gender_cnt:0.8049713373184204\n",
      "earring_cnt:0.8011472225189209|smile_cnt:0.6606118679046631|frontal_face_cnt:0.8049713373184204\n",
      "loss:32.2448\n",
      "checkpoint saved as save_small/02799_0.7538.ckpt\n",
      "E:2799| L:0.731466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2879| L:0.700038:  72%|██████████████████████████████████████▏              | 2879/4000 [4:23:05<1:41:49,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.5577%\n",
      "hair_cnt:0.942638635635376|hair_color_cnt:0.5152963399887085|gender_cnt:0.8173996210098267\n",
      "earring_cnt:0.7934990525245667|smile_cnt:0.6577437520027161|frontal_face_cnt:0.8068833351135254\n",
      "loss:32.1921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:2879| L:0.700038:  72%|██████████████████████████████████████▏              | 2880/4000 [4:23:08<2:00:44,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/02879_0.7556.ckpt\n",
      "E:2879| L:0.700038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:2959| L:0.418800:  74%|███████████████████████████████████████▏             | 2960/4000 [4:30:27<1:51:53,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.1912%\n",
      "hair_cnt:0.9416825771331787|hair_color_cnt:0.5009559988975525|gender_cnt:0.8164435625076294\n",
      "earring_cnt:0.7925429940223694|smile_cnt:0.6443594694137573|frontal_face_cnt:0.8154875636100769\n",
      "loss:31.4218\n",
      "checkpoint saved as save_small/02959_0.7519.ckpt\n",
      "E:2959| L:0.418800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3039| L:1.552638:  76%|████████████████████████████████████████▎            | 3039/4000 [4:37:44<1:28:00,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:74.7929%\n",
      "hair_cnt:0.9455066919326782|hair_color_cnt:0.5|gender_cnt:0.7934990525245667\n",
      "earring_cnt:0.7906309962272644|smile_cnt:0.6500955820083618|frontal_face_cnt:0.8078393936157227\n",
      "loss:32.4406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3039| L:1.552638:  76%|████████████████████████████████████████▎            | 3040/4000 [4:37:48<1:44:31,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/03039_0.7479.ckpt\n",
      "E:3039| L:1.552638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3119| L:0.614195:  78%|█████████████████████████████████████████▎           | 3119/4000 [4:45:05<1:20:03,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.6533%\n",
      "hair_cnt:0.9483747482299805|hair_color_cnt:0.519120454788208|gender_cnt:0.8164435625076294\n",
      "earring_cnt:0.7829827666282654|smile_cnt:0.6558317542076111|frontal_face_cnt:0.8164435625076294\n",
      "loss:31.7255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3119| L:0.614195:  78%|█████████████████████████████████████████▎           | 3120/4000 [4:45:09<1:34:52,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/03119_0.7565.ckpt\n",
      "E:3119| L:0.614195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3199| L:0.552717:  80%|██████████████████████████████████████████▍          | 3199/4000 [4:52:26<1:13:13,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.6533%\n",
      "hair_cnt:0.9512428045272827|hair_color_cnt:0.5076481699943542|gender_cnt:0.8059273362159729\n",
      "earring_cnt:0.7934990525245667|smile_cnt:0.6634799242019653|frontal_face_cnt:0.8173996210098267\n",
      "loss:31.4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3199| L:0.552717:  80%|██████████████████████████████████████████▍          | 3200/4000 [4:52:30<1:27:12,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/03199_0.7565.ckpt\n",
      "E:3199| L:0.552717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3279| L:1.354851:  82%|███████████████████████████████████████████▍         | 3280/4000 [4:59:58<1:16:56,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.9879%\n",
      "hair_cnt:0.9512428045272827|hair_color_cnt:0.49235180020332336|gender_cnt:0.8202676773071289\n",
      "earring_cnt:0.8068833351135254|smile_cnt:0.6653919816017151|frontal_face_cnt:0.8231357336044312\n",
      "loss:32.5007\n",
      "checkpoint saved as save_small/03279_0.7599.ckpt\n",
      "E:3279| L:1.354851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3359| L:0.599832:  84%|████████████████████████████████████████████▌        | 3360/4000 [5:07:28<1:09:19,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.7330%\n",
      "hair_cnt:0.9483747482299805|hair_color_cnt:0.5114722847938538|gender_cnt:0.8173996210098267\n",
      "earring_cnt:0.8059273362159729|smile_cnt:0.6520076394081116|frontal_face_cnt:0.8087953925132751\n",
      "loss:31.3098\n",
      "checkpoint saved as save_small/03359_0.7573.ckpt\n",
      "E:3359| L:0.599832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3439| L:0.745352:  86%|███████████████████████████████████████████████▎       | 3439/4000 [5:14:41<50:51,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.4461%\n",
      "hair_cnt:0.944550633430481|hair_color_cnt:0.509560227394104|gender_cnt:0.8173996210098267\n",
      "earring_cnt:0.7810707688331604|smile_cnt:0.6634799242019653|frontal_face_cnt:0.8107074499130249\n",
      "loss:32.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3439| L:0.745352:  86%|█████████████████████████████████████████████▌       | 3440/4000 [5:14:45<1:00:36,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/03439_0.7545.ckpt\n",
      "E:3439| L:0.745352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3519| L:0.448830:  88%|████████████████████████████████████████████████▍      | 3520/4000 [5:22:03<50:21,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:76.0357%\n",
      "hair_cnt:0.95219886302948|hair_color_cnt:0.5076481699943542|gender_cnt:0.8307839035987854\n",
      "earring_cnt:0.8001912236213684|smile_cnt:0.6625239253044128|frontal_face_cnt:0.8087953925132751\n",
      "loss:31.1746\n",
      "checkpoint saved as save_small/03519_0.7604.ckpt\n",
      "E:3519| L:0.448830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3599| L:2.558661:  90%|█████████████████████████████████████████████████▌     | 3600/4000 [5:29:20<41:47,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.6852%\n",
      "hair_cnt:0.947418749332428|hair_color_cnt:0.4990439713001251|gender_cnt:0.8193116784095764\n",
      "earring_cnt:0.8049713373184204|smile_cnt:0.6520076394081116|frontal_face_cnt:0.8183556199073792\n",
      "loss:33.1884\n",
      "checkpoint saved as save_small/03599_0.7569.ckpt\n",
      "E:3599| L:2.558661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3679| L:0.676140:  92%|██████████████████████████████████████████████████▌    | 3679/4000 [5:36:35<29:15,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.7011%\n",
      "hair_cnt:0.9541109204292297|hair_color_cnt:0.5038241147994995|gender_cnt:0.8145315647125244\n",
      "earring_cnt:0.8011472225189209|smile_cnt:0.6577437520027161|frontal_face_cnt:0.8107074499130249\n",
      "loss:31.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3679| L:0.676140:  92%|██████████████████████████████████████████████████▌    | 3680/4000 [5:36:38<34:57,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/03679_0.7570.ckpt\n",
      "E:3679| L:0.676140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3759| L:0.798181:  94%|███████████████████████████████████████████████████▋   | 3760/4000 [5:43:57<25:23,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:76.3225%\n",
      "hair_cnt:0.9483747482299805|hair_color_cnt:0.5172083973884583|gender_cnt:0.8126195073127747\n",
      "earring_cnt:0.8212236762046814|smile_cnt:0.6682600378990173|frontal_face_cnt:0.8116634488105774\n",
      "loss:32.3512\n",
      "checkpoint saved as save_small/03759_0.7632.ckpt\n",
      "checkpoint saved as save_small/best.ckpt\n",
      "E:3759| L:0.798181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3839| L:1.340962:  96%|████████████████████████████████████████████████████▊  | 3839/4000 [5:51:11<14:32,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.4461%\n",
      "hair_cnt:0.949330747127533|hair_color_cnt:0.5105162262916565|gender_cnt:0.8021032214164734\n",
      "earring_cnt:0.8021032214164734|smile_cnt:0.6577437520027161|frontal_face_cnt:0.8049713373184204\n",
      "loss:32.9315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep:3839| L:1.340962:  96%|████████████████████████████████████████████████████▊  | 3840/4000 [5:51:15<17:13,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/03839_0.7545.ckpt\n",
      "E:3839| L:1.340962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3919| L:1.232528:  98%|█████████████████████████████████████████████████████▉ | 3920/4000 [5:58:33<08:30,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.6214%\n",
      "hair_cnt:0.9502868056297302|hair_color_cnt:0.5066921710968018|gender_cnt:0.8087953925132751\n",
      "earring_cnt:0.8116634488105774|smile_cnt:0.6539196968078613|frontal_face_cnt:0.8059273362159729\n",
      "loss:31.8718\n",
      "checkpoint saved as save_small/03919_0.7562.ckpt\n",
      "E:3919| L:1.232528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3999| L:0.462838: 100%|██████████████████████████████████████████████████████▉| 3999/4000 [6:05:49<00:05,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated on 1046 samples| mean acc:75.6692%\n",
      "hair_cnt:0.9483747482299805|hair_color_cnt:0.49713191390037537|gender_cnt:0.8107074499130249\n",
      "earring_cnt:0.8011472225189209|smile_cnt:0.6673040390014648|frontal_face_cnt:0.8154875636100769\n",
      "loss:31.6671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep:3999| L:0.462838: 100%|███████████████████████████████████████████████████████| 4000/4000 [6:05:52<00:00,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved as save_small/03999_0.7567.ckpt\n",
      "E:3999| L:0.462838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(d)\n",
    "# d = torch.device('cpu')\n",
    "Model = MobileNetV3\n",
    "m = Model().to(d)\n",
    "print(m.mode)\n",
    "train(m,\n",
    "      d,\n",
    "      train_dl,\n",
    "      val_dl,\n",
    "      saveDir=Path('save_small'),\n",
    "      lr=0.0001,\n",
    "      e=4000,\n",
    "      s=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79f49400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded from save_small/best.ckpt\n",
      "epoch: 3759 acc: tensor(0.7632, device='cuda:0')\n",
      "validated on 1046 samples| mean acc:76.3225%\n",
      "hair_cnt:0.9483747482299805|hair_color_cnt:0.5172083973884583|gender_cnt:0.8126195073127747\n",
      "earring_cnt:0.8212236762046814|smile_cnt:0.6682600378990173|frontal_face_cnt:0.8116634488105774\n",
      "loss:32.5743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7632, device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em, epo, acc = load('save_small/best.ckpt')\n",
    "val(Model().to(d).eval(), em.state_dict(), val_dl, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2fc0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}